---
title: "Machine Learning Project"
author: "Hammerer, Ibele, Janez, Romer, Steinwender"
date: "2023-07-29"
output:
  ioslides_presentation:
    widescreen: true
    transition: faster
    highlight: espresso
    css: styles.css
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Versuchsaufbau

1. Experiment
Versuch 1.1 - f1 + 25 Datenpunkte
Versuch 1.1.1 f1 + 25 Datenpunkte + 2 dim 
Versuch 1.1.1.1 f1 + 25 Datenpunkte + 2 dim + Random Sampling + (4, 10*dim, 20*dim)
Versuch 1.1.1.2 f1 + 25 Datenpunkte + 2 dim + Grid Sampling + (4, 10*dim, 20*dim)
Versuch 1.1.1.3 f1 + 25 Datenpunkte + 2 dim + LHS + (4, 10*dim, 20*dim)

Versuch 1.1.2 f1 + 25 Datenpunkte + 3 dim
Versuch 1.1.2.1 f1 + 25 Datenpunkte + 3 dim + Grid Sampling + (popsize = 4)

Versuch 1.2 - f4 + 25 Datenpunkte
Versuch 1.2.1 f4 + 25 Datenpunkte + 2 dim
Versuch 1.2.1.1 f4 + 25 Datenpunkte + 2 dim + Random Sampling + (4, 10*dim, 20*dim)
Versuch 1.2.1.2 f4 + 25 Datenpunkte + 2 dim + Grid Sampling + (4, 10*dim, 20*dim)
Versuch 1.2.1.3 f4 + 25 Datenpunkte + 2 dim + LHS + (4, 10*dim, 20*dim)

Versuch 1.2.2 f4 + 25 Datenpunkte + 3 dim
Versuch 1.2.2.1 f4 + 25 Datenpunkte + 3 dim + LHS + (popsize = 4)


2. Experiment
Versuch 2.1 - f1 + 600 Datenpunkte
Versuch 2.1.1 f1 + 600 Datenpunkte + 2 dim
Versuch 2.1.1.1 f1 + 600 Datenpunkte + 2 dim + Random Sampling + (4, 10*dim, 20*dim)
Versuch 2.1.1.2 f1 + 600 Datenpunkte + 2 dim + Grid Sampling + (4, 10*dim, 20*dim)
Versuch 2.1.1.3 f1 + 600 Datenpunkte + 2 dim + LHS + (4, 10*dim, 20*dim)

Versuch 2.1.2 f1 + 600 Datenpunkte + 3 dim
Versuch 2.1.2.2 f1 + 600 Datenpunkte + 3 dim + Grid Sampling + (popsize = 4)

Versuch 2.2 - f4 + 600 Datenpunkte
Versuch 2.2.1 f4 + 600 Datenpunkte + 2 dim
Versuch 2.2.1.1 f4 + 600 Datenpunkte + 2 dim + Random Sampling + (4, 10*dim, 20*dim)
Versuch 2.2.1.2 f4 + 600 Datenpunkte + 2 dim + Grid Sampling + (4, 10*dim, 20*dim)
Versuch 2.2.1.3 f4 + 600 Datenpunkte + 2 dim + LHS + (4, 10*dim, 20*dim)

Versuch 2.2.2 f4 + 600 Datenpunkte + 3 dim
Versuch 2.2.2.1 f4 + 600 Datenpunkte + 3 dim + Random Sampling + (popsize = 4)


3. Experiment
Versuch 3.1 - 50 Datenpunkte Training + 15 Datenpunkte Test + 300 Epochs + 2 dim
Versuch 3.1.1 f1 + 50 Datenpunkte Training + 15 Datenpunkte Test + 300 Epochs + 2 dim
Versuch 3.1.2 f4 + 50 Datenpunkte Training + 15 Datenpunkte Test + 300 Epochs + 2 dim

Versuch 3.2 - 50 Datenpunkte Training + 15 Datenpunkte Test + 300 Epochs + 3 dim
Versuch 3.2.1 f1 + 50 Datenpunkte Training + 15 Datenpunkte Test + 300 Epochs + 3 dim
Versuch 3.2.2 f4 + 50 Datenpunkte Training + 15 Datenpunkte Test + 300 Epochs + 3 dim

Versuch 3.3 - 1000 Datenpunkte Training + 200 Datenpunkte Test + 100 Epochs + 2 dim
Versuch 3.3.1 f1 + 1000 Datenpunkte Training + 200 Datenpunkte Test + 100 Epochs + 2 dim
Versuch 3.3.1 f4 + 1000 Datenpunkte Training + 200 Datenpunkte Test + 100 Epochs + 2 dim

Versuch 3.4 - 1000 Datenpunkte Training + 200 Datenpunkte Test + 100 Epochs + 3 dim
Versuch 3.4.1 f1 + 1000 Datenpunkte Training + 200 Datenpunkte Test + 100 Epochs + 3 dim
Versuch 3.4.1 f4 + 1000 Datenpunkte Training + 200 Datenpunkte Test + 100 Epochs + 3 dim



## Versuch 1.1.1.1
- kein überragendes Ergebnis, Optimum wird nicht gefunden, RNN ist unbrauchbar, spiegelt Problematik der
realen Welt wieder (begrenzte Anzahl an Datenpunkten)


## Versuch 1.1.1.2
- kein gutes Ergebnis, Optimum wird nicht gefunden, RNN ist unbrauchbar, spiegelt Problematik der
realen Welt wieder (begrenzte Anzahl an Datenpunkten)


## Versuch 1.1.1.3
- kein überragendes Ergebnis, Optimum wird nicht gefunden, RNN ist unbrauchbar, spiegelt Problematik der
realen Welt wieder (begrenzte Anzahl an Datenpunkten)


## Versuch 1.2.1.1
- kein gutes Ergebnis, Optimum wird nicht gefunden, f4 zu konplex, weder globale noch lokale Struktur wird abgebildet, RNN ist unbrauchbar, spiegelt Problematik der
realen Welt wieder (begrenzte Anzahl an Datenpunkten)

## Versuch 1.2.1.2
- kein gutes Ergebnis, Optimum wird nicht gefunden, f4 zu konplex, weder globale noch lokale Struktur wird abgebildet, RNN ist unbrauchbar, spiegelt Problematik der
realen Welt wieder (begrenzte Anzahl an Datenpunkten)

## Versuch 1.2.1.3
- kein gutes Ergebnis, Optimum wird nicht gefunden, f4 zu konplex, weder globale noch lokale Struktur wird abgebildet, RNN ist unbrauchbar, spiegelt Problematik der
realen Welt wieder (begrenzte Anzahl an Datenpunkten)


|-> Versuch 1.1.1 : Grid Sampling am besten, Random Sampling und LHS schneiden gleich schlecht ab, Ergebnisse schlecht, RNN ist unbrauchbar, für 25 Datenpunkte ist die beste Einstellung foglende: 2/5 Grid Sampling, popsize = 4, somit ein 'Gradientenbasierter' Ansatz
|-> Versuch 1.2.1 :  Sampling Methoden auf selben Niveau, Ergebnisse schlecht, RNN ist unbrauchbar, für 25 Datenpunkte ist die beste Einstellung foglende: 2,2/5 LHS, popsize = 4, somit ein 'Gradientenbasierter' Ansatz, Funktion zu komplex



## Versuch 2.1.1.1
- gutes bis sehr gutes Ergebnis, Optimum wurde fast exakt gefunden, RNN ist brauchbar, höher Datenpunktanzahl verbessert das Ergebnis, Optimierung ist sehr langsam auf dem RNN

## Versuch 2.1.1.2
- sehr gutes Ergebnis, Optimum wurde fast exakt gefunden, RNN ist brauchbar, höher Datenpunktanzahl verbessert das Ergebnis, Optimierung ist sehr langsam auf dem RNN

## Versuch 2.1.1.3
- gutes bis sehr gutes Ergebnis, Optimum wurde fast exakt gefunden, RNN ist brauchbar, höher Datenpunktanzahl verbessert das Ergebnis, Optimierung ist sehr langsam auf dem RNN


## Versuch 2.2.1.1
- Ergebnis ausreichend, Optimum wurde fast exakt gefunden jedoch falsches, RNN ist brauchbar, höher Datenpunktanzahl verbessert das Ergebnis, Optimierung ist sehr langsam auf dem RNN


## Versuch 2.2.1.2



## Versuch 2.2.1.3


|-> Versuch 2.1.1 : Grid Sampling am besten, Random Sampling und LHS schneiden gleich gut ab, Ergebnisse gut, RNN ist brauchbar, für 600 Datenpunkte ist die beste Einstellung foglende: 3,6/5 Grid Sampling, popsize = 4, somit ein 'Gradientenbasierter' Ansatz
|-> Versuch 2.2.1 : Random Sampling und LHS gleich gut, Grid Sampling etwas schlechter, Ergebnisse gut, RNN ist brauchbar, für 600 Datenpunkte ist die beste Einstellung foglende: 2,5/5 Random Sampling, popsize = 4, somit ein 'Gradientenbasierter' Ansatz





# Versuch 4.1 - VAE Datenerhebung

Modelleinstellung: siehe Versuchsaufbau Training: 50 Test: 15 Epochs:
300 - Input Daten wurden nicht skaliert - (Versuch) Output Daten x1,x2
auf ursprüngliche Verteilung im Raum zu reskalieren -\> Realität nur
wenige Beobachtungen in der Realität vorhanden

Versuch 4.1.1 

Bild Fuktion ![Alt-Text](images/Versuch%204/GroundtruthF1)

Bild Fuktion zugeschnitten

Bild Datenpunkte zufällig Training
![Alt-Text](images/Versuch%204/DataGenerationRandomTrainF1MinimalData)

Bild Datenpunkte zufällig Test
![Alt-Text](images/Versuch%204/DataGenerationRandomTestF1MinimalData)

Bild Datenpunkte VAE
![Alt-Text](images/Versuch%204/images/Versuch%204/VAEDataF1MinimalData)

Bild Loss Function ![Alt-Text](images/Versuch%204/LossF1MinimalData.png)

### Fazit

-   nicht in der Lage die Verteilung über gesamten Raum zu lernen
-   Globale Struktur wird im begrenzten Ausmaß erlernt
-   Datenpunkteskala passt nur bedingt
-   representiert die 'Realität' nicht ausreichend
-   Loss Function -\> Training und Test Verlauf in Ordnung jedoch nicht
    überagend gut

Versuch 4.1.2

Bild Fuktion ![Alt-Text](images/Versuch%204/GroundtruthF4)

Bild Fuktion zugeschnitten

Bild Datenpunkte zufällig Training
![Alt-Text](images/Versuch%204/DataGenerationRandomTrainF4MinimalData)

Bild Datenpunkte zufällig Test
![Alt-Text](images/Versuch%204/DataGenerationRandomTestF4MinimalData)

Bild Datenpunkte VAE
![Alt-Text](images/Versuch%204/VAEDataF4MinimalData)

Bild Loss Function ![Alt-Text](images/Versuch%204/LossF4MinimalData.png)

### Fazit

-   nicht in der Lage die Verteilung über gesamten Raum zu lernen
-   Globale Struktur wird nicht erkannt
-   Datenpunkteskala passt nur bedingt
-   representiert die 'Realität' nicht
-   Loss Function -\> Training und Test Verlauf in Ordnung jedoch nicht
    überagend gut

---\> Versuch abgebrochen

# Versuch 4.3 - VAE Datenerhebung

Modelleinstellung: siehe Versuchsaufbau Training: 1000 Test: 200 Epochs:
100 - Input Daten wurden nicht skaliert - (Versuch) Output Daten x1,x2
auf ursprüngliche Verteilung im Raum zu reskalieren -\> Realität nur
wenige Beobachtungen in der Realität vorhanden

Versuch 4.3.1 

Bild Fuktion ![Alt-Text](images/Versuch%204/GroundtruthF1)

Bild Fuktion zugeschnitten

Bild Datenpunkte zufällig Training
![Alt-Text](images/Versuch%204/DataGenerationRandomTrainF1MaximalData)

Bild Datenpunkte zufällig Test
![Alt-Text](images/Versuch%204/DataGenerationRandomTestF1MaximalData)

Bild Datenpunkte VAE
![Alt-Text](images/Versuch%204/VAEDataF1MaximalData)

Bild Loss Function ![Alt-Text](images/Versuch%204/LossF1MaximalData.png)

### Fazit

-   bessere Performance + Ergebnisse als bei 50 Datenpunkten
-   Loss Function -\> Training und Test Verlauf gut und benötigt viel
    weniger Epochen
-   lernt Verteilung an sich sehr gut, Problem: scheint
    Dimensionsreduktion anzuwenden, dadurch verzerrte / gestauchte
    Darstellung
-   nicht praktikabel für geplanten Einsatz

Versuch 4.3.1 

Bild Fuktion ![Alt-Text](images/Versuch%204/GroundtruthF4)

Bild Fuktion zugeschnitten

Bild Datenpunkte zufällig Training
![Alt-Text](images/Versuch%204/DataGenerationRandomTrainF4MaximalData)

Bild Datenpunkte zufällig Test
![Alt-Text](images/Versuch%204/DataGenerationRandomTestF4MaximalData)

Bild Datenpunkte VAE
![Alt-Text](images/Versuch%204/VAEDataF4MaximalData)

Bild Loss Function ![Alt-Text](images/Versuch%204/LossF4MaximalData.png)

### Fazit

-   bessere Performance + Ergebnisse als bei 50 Datenpunkten
-   Loss Function -\> Training und Test Verlauf gut und benötigt viel
    weniger Epochen
-   lernt Verteilung an sich sehr gut, Problem: scheint
    Dimensionsreduktion anzuwenden, dadurch verzerrte / gestauchte
    Darstellung
-   nicht praktikabel für geplanten Einsatz
-   (Annahme) lokale Struktur wird erkannt und representiert die
    Funktion

---\> Versuch abgebrochen

\|-\> in Realität ist Groun Truth nicht bekannt, somit ist die
Rekonstruktion nicht möglich \|-\> nicht für den angedachten
Verwendungszweck nicht geeignet \|-\> Ausblick: Modell nochmals
anschauen (Layer, Parameter, etc.), besseres Lernen der Funktion, GAN
oder CVAE ggf. ausprobieren \#

------------------------------------------------------------------------
