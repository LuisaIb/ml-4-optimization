---
title: "Machine Learning Project"
author: "Hammerer Lena, Ibele Luisa, Janez Isabel, Romer Judith, Steinwender Hanna"
date: "2023-09-08"
output:
  ioslides_presentation:
    widescreen: true
    transition: faster
    highlight: espresso
    css: styles.css
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Gliederung

-   Motivation und Zielsetzung
-   Vorgehen und Methodik
-   Versuchsaufbau
-   Bewertungsmatrix
-   Umsetzung und Auswertung
-   Schlussbetrachtung

# Motivation und Zielsetzung

Hanna Steinwender

## Motivation

-   Entwicklung und Bewertung von Optimierungsalgorithmen in realen
    Anwendungen
-   Herausforderung traditioneller Bewertung mit statischen
    Testdatensätzen
-   Notwendigkeit von Testfunktionen für Algorithmen
-   Schwierigkeit bei der Suche nach passenden Testfunktionen
-   Begrenzte Verfügbarkeit von Ground-Truth-Funktionen
-   Modelle mit realen Daten als Ersatz für Ground-Truth-Funktionen
    erstellen

## Zielsetzung

-   Entwicklung von Testfunktionen
-   Approximation von Ground-Truth-Funktionen
-   Erfüllung von Anforderungen: Difficulty, Diversity, Flexibility,
    Relevance, Evaluation cost, Non-Smoothing
-   Validierung durch Vergleich mit BBOB Function Suite
-   Beitrag zur Optimierungsalgorithmen-Forschung
-   Anwendbarkeit in realen Optimierungsaufgaben

## Forschungsfragen

1.  Ist der Einsatz eines Variational Autoencoder (VAE) als
    Datenerhebungstrategie sinnvoll?
2.  Ist ein Deep Neural Networks (DNN) basierend auf der erstellten
    Bewertungsmatrix geeignet zur Erzeugung der Testfunktion?
3.  Ist der Einsatz eines DNNs auf Basis der Kriterien aus der
    Zielsetzung geeignet?

# Vorgehen und Methodik

Hanna Steinwender

## Vorgehen und Methodik

<br><br>

<center><x>![](images/method.png){width="90%"}</center>

# Versuchsaufbau

Lena Hammerer

## Groundtruths

-   *wahre* / *korrekte* Vorhersage für ein gegebenes Problem
-   Referenzpunkt, um die Leistung von ML-Modellen zu bewerten und ihre
    Qualität sicherzustellen
-   Probleme in der Praxis:
    -   (noch) nicht verfügbar
    -   teuer in der Auswertung, eingeschränkte
        Experimentiermöglichkeiten
    -   vertraulich (Veröffentlichung nicht möglich)

[Hansen, N., Auger, A., Mersmann, O., Tušar, T. and Brockhoff, D., 2016.
COCO: A platform for comparing continuous optimizers in a black-box
setting. ArXiv e-prints. arXiv preprint arXiv:1603.08785,
172.]{style="font-size: 14px"}

## Groundtruths

-   **f1 Sphere Function**
    -   einfachstes kontinuierliches Domänensuchproblem, da unimodal und
        hochsymmetrisch
-   **f24 Lunacek bi-Rastrigin Function**
    -   Hoch multimodal und trügerisch für evolutionäre Algorithmen mit
        großer Populationsgröße

![](images/GroundtruthF1){width="47%"}![](images/GroundtruthF24){width="47%"}

## Variable Parameter

Ground-Truth-Funktion f1 und f24 mit jeweils 2 oder 3 Dimensionen

``` r:
numBbobf <- 1/24
dim <- 2/3
```

25 oder 600 Datenpunkten mit Random/Grid Sampling oder LHS

``` r:
dataGenerationMethod <- "lhs", "random", "grid"
numDataPoints <- 25/600
```

Split von Trainings- und Evaluationsdaten für die Modellierung

``` r:
trainTestSplit <- 0.8
```

Funktion 200 oder 400 mal evaluieren

``` r:
funEval <- 200/400
```

## Datenerhebungstrategie

**Random Sampling**

-   zufällige werte für `x` und `y` generieren
-   Reproduzierbar durch Random Seed
-   Verteilung entspricht ggf. nicht den tatsächlichen Daten
-   Erzeugung innerhalb von fixen Grenzen

**Grid Sampling**

-   vordefinierte Menge von Parameterkombinationen
-   Reproduzierbar, da jeder Punkt im Parameterraum einmal besucht
-   Fluch der Dimensionen
-   besser geeignet für diskrete Parameter

## Datenerhebungstrategie

**Latin Hypercube Sampling**

-   Kombination der RS und GS Ansätze
-   Parameterraum in gleich wahrscheinliche Intervalle oder Bins entlang
    jeder Dimension unterteilt
-   Aus jedem Bin wird ein Zufallswert ausgewählt
-   Gleichmäßige Verteilung von Stichprobenpunkte über den Parameterraum
-   Repräsentativität wird erhöht

[McKay, M.D., Beckman, R.J. and Conover, W.J., 2000. A Comparison of
Three Methods for Selecting Values of Input Variables in the Analysis of
Output From a Computer Code. Technometrics, 42(1),
pp.55-61.]{style="font-size: 14px"}

## Modellaufbau DNN

**Depp Neural Network for Regression**:

|                    |                                       |                   |
|--------------------|---------------------------------------|-------------------|
| Eingangsschicht    | layer_dense(units=128, input_shape=2) | Leaky ReLU        |
| Verborgene-Schicht | layer_dense(units=32)                 | Leaky ReLU        |
| Verborgene-Schicht | layer_dense(units=128)                | Leaky ReLU        |
| Dropout-Schicht    | layer_dropout(rate=0.001)             | \-                |
| Verborgene-Schicht | layer_dense(units=64)                 | Leaky ReLU        |
| Ausgangsschicht    | layer_dense(units=1)                  | Linear Activation |

## Modellaufbau DNN

**Mean Squared Logarithmic Error**

-   besonders nützlich wenn Zielgrößen stark variieren.

$$
\text{MSE Log Error} = \frac{1}{N} \sum_{i=1}^{N} (\log(y_i + 1) - \log(\hat{y}_i + 1))^2
$$

**Adam Optimizer**

-   SGD-Methode, die auf der adaptiven Schätzung von Momenten erster und
    zweiter Ordnung beruht
-   gut geeignet für Probleme mit großer Anzahl von Daten/Parametern

[Kingma, D.P. and Ba, J., 2014. Adam: A Method for Stochastic
Optimization. arXiv preprint arXiv:1412.6980.]{style="font-size: 14px"}

## Optimierung mit Differential Evolution

-   Metaheuristik zur globalen Optimierung von Problemen
-   Population von Kandidatenlösungen, Mutation, Rekombination und
    Selektion, um schrittweise bessere Lösungen zu finden
-   besonders für nichtdifferenzierbare Zielfunktionen und Probleme ohne
    spezielle Struktur geeignet

**Populationsgröße**: Anzahl gleichzeitig betrachteter Lösungen

-   klein =\> schnell, aber ggf. vorzeitige Kovergenz zu lokalen Optima
-   groß =\> ggf. bessere Lösungen, aber mehr Rechenleistung

``` r:
popSize = 4
popSize = 10\*dim
popSize = 20\*dim
```

# Bewertungsmatrix

Luisa Ibele

## Grundlegendes Bewertungsschema

-   Grundlegende Parameter der einzelnen Versuchsdurchläufe:
    -   Anzahl Datenpunkte
    -   Datenerhebungsstrategie
    -   Funktion
    -   Dimensionen
-   Bewertung der Modelle und Optimierung anhand verschiedener Kriterien

## Grundlegendes Bewertungsschema

-   Bewertungsskala von 1 bis 5 Punkten mit:
    -   1: sehr schlecht, schwach
    -   2: schlecht, unterhalb des Erwarteten
    -   3: durschnittlich, akzeptabel
    -   4: gut, über dem Erwarteten
    -   5: sehr gut, ausgezeichnet

## Modellbewertung

<center><x> ![](images/modelMatrix.PNG){width="100%"}</center>

## Gewichtung

-   Durchschnittlicher Trainingsloss - 10%
-   (Visual) Loss Function Verlauf - 30%
-   (Visual) Generated Function vs. Original Function - 40%
-   Performance - 20%

## Optimierungsbewertung

<center><x> ![](images/optimizationMatrix.PNG){width="80%"}</center>

## Gewichtung

-   Optimum Wert - 30%
-   Performance - 20%
-   Error / Evaluations - 20%
-   Y / Evaluations - 30%

## Finale Bewertungsmatrix

<center><x> ![](images/generalMatrix.PNG){width="80%"}</center>

## Gesamtbewertung

-   Gewichtung:
    -   Modellbewertung - 30%
    -   Optimierungsbewertung - 70%
-   Systematische Analyse und Bewertung der Versuche im Rahmen der
    Modell- und Optimierungsbewertung
-   Fundierte Beurteilung der Modellleistung, Optimierungsalgorithmen
    und Versuche anhand der gewählten Bewertungskriterien
-   Berücksichtigung qualitativer und quantitativer Aspekte
-   Bewertung des gesamten Versuchs möglich

## Versuchsbewertung

Bewertung der einzelnen Versuche anhand von:

-   Difficulty
-   Diversity
-   Flexibility
-   Relevance
-   Evaluation cost
-   Non-Smoothing

[Zaefferer, M., Fischbach, A., Naujoks, B. and Bartz-Beielstein, T.,
2017, July. Simulation-based Test Functions for Optimization Algorithms.
In Proceedings of the genetic and evolutionary computation conference
(pp. 905-912).]{style="font-size: 14px"}

# Umsetzung

Luisa Ibele

## Übersicht 1. Experiment

<x> ![](images/Experiment1.png){width="100%"}

## Übersicht 2. Experiment

<x> ![](images/Experiment2.png){width="100%"}

## Übersicht 3. Experiment

<x> ![](images/Experiment3.png){width="100%"}

# Auswertung

# Eperiment 1

Judith Romer

## Versuch 1.1.1.2 - Bildvergleich

<center>

<x>![](images/GroundtruthF1){width="42%"}

<x>![](images/Versuch1.1.1.2DNNFunction){width="42%"}![](images/Versuch1.1.1.2GaussFunction){width="42%"}

</center>

## Versuch 1.1.1.2 - Y Wert / Evaluation

![](images/Versuch1.1.1.2DE4YAllThree){width="47%"}![](images/Versuch1.1.1.2DEDimx10YAllThree){width="47%"}

|                     |                                       |
|---------------------|---------------------------------------|
| Population Size = 4 | **Population Size = 10 \* Dimension** |
| Verborgene-Schicht  | **layer_dense(units=32)**             |
| Verborgene-Schicht  | **layer_dense(units=128)**            |

## Versuch 1.1.1.2 - Fehler / Evaluation

![](images/Versuch1.1.1.2DE4Error){width="47%"}![](images/Versuch1.1.1.2DEDimx10Error){width="47%"}

# Experiment 2

Judith Romer

## Versuch 2.2.1.1 - Bildvergleich 2D

<center>

<x>![](images/GroundtruthF24){width="42%"}

<x>![](images/Versuch2.2.1.1DNNFunctionRandom){width="42%"}![](images/Versuch2.2.1.1GaussFunctionRandom){width="42%"}

</center>

## Versuch 2.2.2.1 - Bildvergleich 3D

<br> <br>
![](images/GIFF24.gif){width="47%"}![](images/GIFDNN.gif){width="47%"}

## Versuch 2.2.1.1 & 2.2.2.1 - Y Wert / Evaluation

<br> <br>
![](images/Versuch2.2.1.1DE4YAllThree){width="47%"}![](images/Versuch2.2.2.1DE4YAllThree){width="47%"}

## Versuch 2.2.1.1 & 2.2.2.1 - Fehler / Evaluation

<br> <br>
![](images/Versuch2.2.1.1DE4Error){width="47%"}![](images/Versuch2.2.2.1DE4Error){width="47%"}

# Experiment 3

Isabel Janez

## VAE mit 50 Datenpunkten Funktion 1

<br> <br>
![](images/DataGenerationRandomTrainF1MinimalData){width="47%"}![](images/VAEDataF1MinimalData){width="47%"}

## VAE mit 1000 Datenpunkten Funktion 1

<br> <br>
![](images/DataGenerationRandomTrainF1MaximalData){width="47%"}![](images/VAEDataF1MaximalData){width="47%"}

## VAE mit 50 Datenpunkten Funktion 24

<br> <br>
![](images/DataGenerationRandomTrainF24MinimalData){width="47%"}![](images/VAEDataF24MinimalData){width="47%"}

## VAE mit 1000 Datenpunkten Funktion 24

<br> <br>
![](images/DataGenerationRandomTrainF24MaximalData){width="47%"}![](images/VAEDataF24MaximalData){width="47%"}

# Beantwortung der Forschungsfragen

Isabel Janez

## Ist der Einsatz eines Variational Autoencoder als Datenerhebungstrategie sinnvoll?

-   Versuch wurde abgebrochen → sehr schlechte Ergebnisse vor allem bei
    50 Datenpunkten
-   nicht in der Lage die Verteilung über gesamten Raum zu lernen
-   Datenpunkteskala passt nur bedingt
-   representiert die 'Realität' nicht ausreichend
-   Dimensionsreduktion führt zu Problemen, dadurch verzerrte /
    gestauchte Darstellung

für das vorliegende Problem konnte der VAE nicht zur Datenerhebung
eingesetzt werden

weiteres Vorgehen:

-   Modellarchitektur überarbeiten
-   Generative Adversial Network (GAN)
-   Conditional Variational Autoencoder (CVAE)

## Ist ein Deep Neural Networks (DNN) basierend auf der erstellten Bewertungsmatrix geeignet zur Erzeugung der Testfunktion?

-   Threshold: 4 / 5

-   DNN = 4 → gleich gut wie GPM

-   DNN \> 4 → besser als GPM

-   Experiment 1: 2,13 / 5

-   Experiment 2: 3 / 5

Im vorliegenden Fall: DNN liegt unter Threshold, somit nicht geeignet

## Ist der Einsatz eines DNNs auf Basis der Kriterien aus der Zielsetzung geeignet?

-   Threshold: 3 / 5

-   [4\|5] Difficulty

-   [3\|5] Diversity

-   [3\|5] Flexibility

-   [1\|5] Relevance

-   [1\|5] Evaluation cost

-   [1\|5] Non-Smoothing

-   DNN: 2,2 / 5

im vorliegenden Fall: DNNs liegt unter Threshold, somit nicht geeignet

# Schlussbetrachtung

Isabel Janez

## Fazit

-   Graußsche Prozessmodelle im vorliegenden Anwendungsfall besser
    geeignet
-   Anmerkung: es wurde nur die Estimation verglichen; kein Vergleich
    von Simulation
-   Tradeoff zwischen Rechenleistung und Komplexität des DNN

## Ausblick

-   Abbildung der lokalen Struktur mit dem neuronalen Netz durch
    Erstellung neuer Loss-Funktion, die nicht nur einzelne Punkte
    optimiert, sondern mehrere Punkte betrachtet
-   Vergleich von Graußscher Prozessmodell Simulation anstelle von
    Estimation

# Vielen Dank für die Aufmerksamkeit! Noch Fragen?

## Prüfungsleistung Aufteilung

-   Hanna Steinwender: Folie 1 bis Folie 8
-   Lena Hammerer: Folie 9 bis Folie 17
-   Luisa Ibele: Folie 18 bis Folie 26
-   Judith Romer: Folie 26 bis Folie 39
-   Isabel Janez: Folie 40 bis 57
