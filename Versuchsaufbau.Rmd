---
title: "Machine Learning Project"
author: "Hammerer, Ibele, Janez, Romer, Steinwender"
date: "2023-07-29"
output:
  ioslides_presentation: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Forschungsfragen:
1. Ist der Einsatz eines Variational Autoencoder als Datenerhebungstrategie sinnvoll? (VAE Experiment)
2. Ist ein RNN besser als ein Gauss bei der Optimierung? (Bewertungsmatrix Optimierung)
3. Ist der Einsatz von RNN geeignet? (Versuchkriterien)





# Verworfene Ansätze
- VAE für Regression
- VAE wegen Dimensionsreduktion nicht für Datenerhebung geeignet
- Loss Function selber schreiben
- L-BFGS-B als Optimierer




# Investigation

## Phase 1 Datenerhebungsstrategien

Unterschiedliche Herangehensweisen zur Erstellung von Datenpunkten aus der Ground Truth Funktion:


### Grid Sampling
Vorteile:
- Anpassungsfähigkeit: Die Funktion erlaubt es, die Anzahl der zu generierenden Datenpunkte n als Eingabeparameter anzugeben. Dadurch kann die Menge der generierten Daten leicht kontrolliert werden.
- Flexibilität bei der Funktionswahl: Die Funktion akzeptiert eine beliebige Funktion f, die abhängig von den Koordinaten x und y den Wert z berechnet. Dadurch kann die Funktion generateDataPoints vielseitig für verschiedene Anwendungen eingesetzt werden, indem man unterschiedliche Funktionen f übergeben kann.
- Zufällige Verteilung: Die Funktion runif() wird verwendet, um Zufallswerte für x und y zu generieren. Dadurch werden die Datenpunkte in einem zufälligen Bereich innerhalb der durch getLowerBoxConstraints(ftest) und getUpperBoxConstraints(ftest) definierten Box erzeugt. Dies kann hilfreich sein, um eine breitere Palette von Szenarien und Randbedingungen abzudecken.
- Einfachheit: Die Funktion verwendet grundlegende R-Funktionen, wie runif() und apply(), um die Datenpunkte zu generieren und den Funktionswert z zu berechnen. Dies macht die Funktion einfach und leicht verständlich.
- Geschwindigkeit: Die Funktion nutzt eingebaute R-Funktionen zur Generierung der Datenpunkte. Dadurch kann sie in der Regel effizient und schnell arbeiten, auch für größere Datenmengen.


Nachteile: 
- Begrenzte Datenerzeugung: Die Funktion generiert Datenpunkte, indem sie Zufallszahlen innerhalb einer definierten Box verwendet. Dies kann dazu führen, dass die Verteilung der generierten Daten nicht genau den tatsächlichen Daten entspricht. Die Daten könnten ungleichmäßig oder in bestimmten Bereichen dichter sein, was möglicherweise nicht die tatsächliche Verteilung der Daten in der realen Welt widerspiegelt. 
- Fixe Boxgrenzen: Die Funktion verwendet feste Grenzen (lower und upper) für die generierten Datenpunkte. Wenn die tatsächlichen Daten in einem anderen Bereich liegen oder sich die Verteilung im Laufe der Zeit ändert, könnten die generierten Datenpunkte möglicherweise nicht repräsentativ für das reale Szenario sein. 
- Zufälligkeit: Die Verwendung von Zufallszahlen zur Generierung der Datenpunkte kann dazu führen, dass bei jeder Ausführung der Funktion unterschiedliche Datenpunkte erzeugt werden. Dies kann die Reproduzierbarkeit von Experimenten oder Analysen erschweren. - Begrenzte Dimensionen: Die Funktion ist auf 2D-Datenpunkte beschränkt (x und y). Wenn du mehrdimensionale Datenpunkte generieren möchtest, müsstest du die Funktion entsprechend anpassen.


### Grid Sampling
Vorteile:
- Exploration des Parameterraums: Grid Sampling ermöglicht eine umfassende Erkundung des Parameterraums, indem es eine vordefinierte Menge von Parameterkombinationen erstellt. Dadurch werden verschiedene Kombinationen von Hyperparametern ausprobiert, um diejenigen zu finden, die das Modell am besten optimieren.
- Einfachheit und Einfachheit der Implementierung: Grid Sampling ist einfach zu implementieren und erfordert keine komplexen Optimierungsalgorithmen oder heuristische Ansätze. Es ist leicht verständlich und kann auch auf einfache Weise parallelisiert werden, um das Training zu beschleunigen.
- Reproduzierbarkeit: Grid Sampling ist deterministisch und reproduzierbar, da es jeden Punkt im Parameterraum genau einmal besucht. Dadurch können die Ergebnisse einfach wiederholt werden.
- Vergleichbarkeit: Durch die systematische Auswertung verschiedener Parameterkombinationen ermöglicht Grid Sampling einen direkten Vergleich der Leistung verschiedener Modelle unter den gleichen Bedingungen.
- Geringe Anforderungen an die Datenmenge: Grid Sampling kann auch mit begrenzten Datenmengen durchgeführt werden, da es nicht auf große Datenmengen angewiesen ist, um eine aussagekräftige Optimierung durchzuführen.

Nachteile:
- Hoher Rechenaufwand: Grid Sampling kann sehr zeitaufwändig sein, insbesondere bei großen Parameterräumen oder komplexen Modellen. Da es alle möglichen Kombinationen ausprobiert, steigt die Anzahl der Modelltrainings exponentiell mit der Anzahl der Hyperparameter und ihrer möglichen Werte.
- Ineffizient bei großen Parameterräumen: Wenn der Parameterraum groß ist oder wenn die Hyperparameter viele mögliche Werte haben, kann Grid Sampling sehr ineffizient sein. Die meisten der Parameterkombinationen werden möglicherweise nicht zu einer wesentlichen Verbesserung des Modells führen, dennoch werden sie alle evaluiert.
- Fehlende Berücksichtigung der Beziehungen zwischen Hyperparametern: Grid Sampling betrachtet jede Kombination von Hyperparametern unabhängig voneinander. Es berücksichtigt möglicherweise nicht, wie sich bestimmte Hyperparameterkombinationen gegenseitig beeinflussen oder welche Abhängigkeiten zwischen ihnen bestehen.
- Overfitting des Hyperparameterraums: Wenn Grid Sampling auf derselben Datensatzpartition ausgeführt wird, die auch für die Modelloptimierung verwendet wird, besteht die Gefahr von Overfitting des Hyperparameterraums. Es kann sein, dass Grid Search zufällig die besten Hyperparameterkombinationen für diese spezielle Datensatzpartition findet, die jedoch möglicherweise nicht gut auf anderen Daten verallgemeinern.
- Nicht geeignet für kontinuierliche Hyperparameter: Grid Sampling eignet sich am besten für diskrete Hyperparameter, bei denen die möglichen Werte aus einer festen Menge ausgewählt werden können. Für kontinuierliche Hyperparameter ist es nicht praktikabel, alle möglichen Werte im Parameterraum auszuprobieren.
- Fehlende Optimierung: Grid Search ist ein einfacher, nicht-optimierender Ansatz. Es garantiert nicht, dass die gefundenen Hyperparameter die besten für das Modell sind. Andere Optimierungsalgorithmen wie Random Search oder Bayesian Optimization können möglicherweise effizienter sein, um eine gute Kombination von Hyperparametern zu finden.


### Latin Hypercube Sampling

Vorteile: 
- Effizienz und Verteilungsausgleich: LHS ermöglicht eine effiziente Abdeckung des Parameterraums mit einer begrenzten Anzahl von Proben. Im Gegensatz zu Grid Sampling, das alle möglichen Kombinationen ausprobiert, teilt LHS den Parameterraum in gleichmäßige Intervalle auf und entnimmt jeweils eine Probe aus jedem Intervall. Dadurch wird der Parameterraum gut abgedeckt, ohne dass zu viele unnötige Proben in nicht wichtigen Bereichen durchgeführt werden. 
- Verbesserte Explorationsfähigkeit: LHS bietet eine bessere Exploration des Parameterraums im Vergleich zu einfachen Zufallsstichproben. Durch die gleichmäßige Abdeckung des Parameterraums wird sichergestellt, dass wichtige Regionen nicht übersehen werden, und dass verschiedene Hyperparameterkombinationen effizient ausprobiert werden. 
- Reduziertes Risiko von Overfitting: LHS ermöglicht eine bessere Generalisierung der Ergebnisse, da es die Proben gleichmäßig über den Parameterraum verteilt. Dadurch wird das Risiko von Overfitting reduziert, da die Auswahl von Proben weniger anfällig für zufällige Ausreißer oder stark ungleichmäßige Verteilungen ist. 
- Verbesserte Reproduzierbarkeit: LHS kann so konfiguriert werden, dass die generierten Proben reproduzierbar sind, indem die gleiche Zufallsseed verwendet wird. Dies erleichtert die Wiederholbarkeit von Experimenten und Analysen. 
- Effiziente Verwendung von Ressourcen: Da LHS eine begrenzte Anzahl von Proben verwendet, kann es effizientere Ressourcennutzung ermöglichen, insbesondere wenn die Anzahl der Hyperparameter oder die Dimensionalität des Parameterraums hoch ist. 
- Kontinuierliche Hyperparameterunterstützung: LHS eignet sich gut für kontinuierliche Hyperparameter, bei denen die möglichen Werte in einem Bereich liegen. Es kann die Hyperparameter gleichmäßig auf diesem Bereich verteilen. 
- Verbesserte Optimierung: Im Vergleich zu Grid Search führt LHS eine bessere Optimierung des Parameterraums durch, da es eine effiziente und gleichmäßige Abdeckung ermöglicht, was zu einer schnelleren und genaueren Suche nach guten Hyperparameterkombinationen führt.

Nachteile: 
- Komplexität der Implementierung: Die Implementierung von LHS kann im Vergleich zu einfachen Zufallsstichproben oder Grid Sampling etwas komplexer sein. Es erfordert eine zusätzliche Logik, um die gleichmäßige Verteilung der Proben im Parameterraum sicherzustellen. 
- Schwierigkeiten bei hochdimensionalen Räumen: LHS kann in hochdimensionalen Parameterräumen schwieriger und weniger effizient sein, da die gleichmäßige Abdeckung schwieriger wird. In solchen Fällen können andere Methoden wie Monte Carlo-Methoden oder Bayesian Optimization vorteilhafter sein. 
- Abhängigkeit von der Anzahl der Proben: Die Leistung von LHS hängt von der Anzahl der Proben ab, die ausgewählt werden. Eine zu kleine Anzahl von Proben kann die Effizienz und Genauigkeit der Abdeckung des Parameterraums beeinträchtigen. 
- Unvollständige Abdeckung bei begrenzten Proben: In einigen Fällen, insbesondere wenn die Anzahl der Proben begrenzt ist, kann LHS den Parameterraum möglicherweise nicht vollständig abdecken, was zu einer möglichen Unterrepräsentation bestimmter Hyperparameterkombinationen führt. 
- Keine Optimierungsgarantie: Obwohl LHS eine bessere Optimierung als Grid Search bietet, garantiert es nicht, dass die gefundenen Hyperparameterwerte die besten für das Modell sind. Es ist immer noch möglich, dass wichtige Hyperparameterkombinationen unentdeckt bleiben. 
- Statische Verteilung: LHS teilt den Parameterraum in gleichmäßige Intervalle auf und wählt jeweils eine Probe aus jedem Intervall. Dies kann dazu führen, dass die Verteilung der Proben statisch bleibt, was möglicherweise nicht ideal ist, wenn die Funktion f im Parameterraum nicht gleichmäßig ist. 
- Nicht ideal für multimodale Verteilungen: Wenn der Parameterraum multimodal ist und wichtige Bereiche mit unterschiedlicher Dichte oder Anzahl von Moden aufweist, kann LHS möglicherweise nicht die besten Ergebnisse liefern.


### Dimensionen

Funktion f1: Die Funktion f1 ist eine Benchmark-Funktion (Testfunktion) mit 2-dimensionalen Eingabedaten. Sie gehört zu den "BBOB" (Black-Box Optimization Benchmarking) Funktionen, die in der "smoof" Bibliothek enthalten sind. BBOB-Funktionen sind standardisierte Testfunktionen, die in der Optimierungsforschung verwendet werden, um Algorithmen für die globale Optimierung zu vergleichen und zu evaluieren. Die genaue mathematische Definition der f1-Funktion kann im Quellcode der "smoof" Bibliothek nachgesehen werden.

Funktion f4: Die Funktion f4 ist ebenfalls eine Benchmark-Funktion mit 2-dimensionalen Eingabedaten aus der BBOB-Funktionsgruppe. Wie f1 gehört sie zu den standardisierten Testfunktionen, die in der Optimierungsforschung verwendet werden. Genauere Details zur mathematischen Definition der f4-Funktion können im Quellcode der "smoof" Bibliothek gefunden werden.


------------------------------------------------------------------------------------------------------------------



## Phase 2 Modellentwicklung und Modellauswahl

### Variational Autoencoder

Modelldefinition:
- Der Variational Autoencoder (VAE) besteht aus zwei Hauptkomponenten: einem Encoder-Netzwerk und einem Decoder-Netzwerk.
- Das Encoder-Netzwerk verwendet mehrere Dense-Layer, um die Eingabedaten schrittweise in eine niedrigdimensionale Latent-Space-Repräsentation zu transformieren.
- Das Decoder-Netzwerk ist das Gegenstück zum Encoder und rekonstruiert die ursprünglichen Eingabedaten aus der Latent-Space-Repräsentation.
- Der Latent-Space hat eine vorgegebene Dimension (latent_dim), die im Code auf 2 festgelegt ist.
- Die Latent-Space-Repräsentation wird durch den Mean (z_mean) und den Logarithmus der Varianz (z_log_var) definiert.

Encoder:
- Der erste Dense-Layer (h) hat intermediate_dim Neuronen und verwendet die ReLU-Aktivierungsfunktion, um nicht-lineare Eigenschaften der Daten zu erfassen.
- Der zweite Dense-Layer (i) hat ebenfalls intermediate_dim Neuronen und führt weitere nicht-lineare Transformationen mithilfe der ReLU-Aktivierungsfunktion durch.
- Die letzten beiden Dense-Layer (z_mean und z_log_var) bestehen aus latent_dim Neuronen, wobei latent_dim die Dimension des Latent-Space ist. z_mean repräsentiert den Mittelwert der Latent-Space-Repräsentation, während z_log_var den Logarithmus der Varianz darstellt.

Decoder:
- Der erste Dense-Layer (decoder_h) besteht aus intermediate_dim Neuronen und verwendet die ReLU-Aktivierungsfunktion für nicht-lineare Transformationen.
- Der zweite Dense-Layer (decoder_mean) hat input_dim Neuronen, wobei input_dim die Dimension der ursprünglichen Eingabedaten ist. Hier wird die lineare Aktivierungsfunktion verwendet, um die ursprünglichen Eingabedaten zu rekonstruieren.

Sampling-Funktion:
- Die Sampling-Funktion generiert Latent-Space-Punkte und verwendet z_mean und z_log_var als Eingabe.
- Die "Reparameterization Trick" wird angewendet, indem ein normalverteilter Zufallsvektor mit geringer Varianz (durch epsilon_std gesteuert) multipliziert und zum z_mean addiert wird.

Kompilierung des Modells:
- Das gesamte VAE-Modell wird durch Verketten von Encoder- und Decoder-Netzwerken erstellt.
- Das Modell wird mit dem VAE-Loss (vae_loss) kompiliert, der aus einer Kombination von Mean Squared Error (MSE) und Kullback-Leibler (KL)-Divergenz besteht. MSE misst den Rekonstruktionsfehler, während KL-Divergenz die Ähnlichkeit der Latent-Space-Repräsentation mit einer Standardnormalverteilung misst.

Training des Modells:
- Das VAE-Modell wird mit den Trainingsdaten (input_data) trainiert, die in der Variable dfF1 im Code enthalten sind.
- Der Adam-Optimizer mit einer Lernrate von 0.0001 wird verwendet.
- Das Training erfolgt über eine bestimmte Anzahl von Epochen (epochs) und in Batches (batch_size).
- Das Modell wird auch mit den Testdaten (test_data) validiert, um die Leistung zu überwachen.

------------------------------------------------------------------------


### Versuchsaufbau mit automatisierter Datenerhebung und RNN Modell

Erforderliche Pakete: Der Code beginnt mit dem Laden verschiedener R-Pakete, die für den Versuchsaufbau benötigt werden, darunter smoof für Benchmark-Testfunktionen, ggplot2 für Diagramme, keras für neuronale Netzwerke, SPOT für Optimierungsalgorithmen, pracma für praktische Mathematikfunktionen, lhs für Latin-Hypercube-Abtastung, COBBS für Modellierung von Funktionen und kernlab für Support Vector Machines und Gauß'sche Prozesse.

Einstellungen und Anpassungen: Hier werden verschiedene Parameter eingestellt, darunter die Anzahl der Benchmark-Testfunktionen (numBbobf), die Dimension der Funktionen (dim) - 2 und 3, die Methode zur Generierung von Daten (dataGenerationMethod) - Random Sampling, Grid Sampling und LHS, die Anzahl der Datenpunkte (numDataPoints) - 25 und 600, die Aufteilung von Trainings- und Testdaten (trainTestSplit) und die Anzahl der Funktionsauswertungen (funEval).

Laden der Funktionen: Die Funktionen für die Erstellung von Testfunktionen, die Erstellung von 2D-Funktionsplots und das Anzeigen der Testfunktionen werden definiert - f1 und f24.

Laden und Darstellen der Testfunktionen: Die ausgewählten Benchmark-Testfunktionen werden geladen und ihre unteren und oberen Schranken werden abgerufen. Wenn die Dimension 2 ist, wird eine Funktion zum Erstellen eines 2D-Plots der Testfunktionen aufgerufen.

Generieren der Trainingsdaten: Funktionen zum Generieren von Datenpunkten durch zufällige, gitterbasierte oder Latin-Hypercube-Abtastung werden definiert. Die Funktion generateDataPoints wird verwendet, um Trainingsdaten unter Verwendung der ausgewählten Methode zu generieren. Bei Dimension 2 werden die generierten Datenpunkte in einem Streudiagramm dargestellt.

Aufteilung von Trainings- und Testdaten: Die generierten Daten werden in Trainings- und Testdaten aufgeteilt, wobei der angegebene Trainings-Test-Split (trainTestSplit) verwendet wird.

Erstellen eines RNN-Modells: Eine Funktion zur Erstellung eines sequentiellen neuronalen Netzwerkmodells (RNN) wird definiert. Das Modell besteht aus mehreren Schichten von dichten Neuronen. Das Modell wird mit den Trainingsdaten trainiert und die Trainingszeit wird aufgezeichnet.
Der Aufbau des RNN-Modells ist wie folgt:

Eingangsschicht: layer_dense(units=128, input_shape=2) mit aktivierender "Leaky ReLU"-Funktion.
Verborgene Schicht: layer_dense(units=32) mit aktivierender "Leaky ReLU"-Funktion.
Verborgene Schicht: layer_dense(units=128) mit aktivierender "Leaky ReLU"-Funktion.
Dropout-Schicht: layer_dropout(rate=0.001) mit einer Auslassrate von 0.001.
Verborgene Schicht: layer_dense(units=64) mit aktivierender "Leaky ReLU"-Funktion.
Ausgangsschicht: layer_dense(units=1, activation="linear") für die lineare Ausgabe.
Das Modell verwendet den Mean Squared Logarithmic Error als Verlustfunktion und den Adam-Optimizer für das Training.

Erstellen eines Regressionsmodells (Gaußprozess): Ein Gaußprozess-Regressionsmodell wird unter Verwendung der Funktion kernlab::gausspr erstellt. Die Trainingszeit wird gemessen und aufgezeichnet.

Generieren der Grundwahrheit: Eine Funktion wird erstellt, die die tatsächlichen Funktionswerte basierend auf den Trainingsdaten und der Benchmark-Testfunktion generiert.

Der Versuchsaufbau nutzt maschinelles Lernen, um Optimierungsalgorithmen auf Benchmark-Testfunktionen anzuwenden. Durch das Trainieren von RNN-Modellen und Regressionsmodellen werden die besten Parameter für die gegebenen Testfunktionen ermittelt. Die Generierung der Grundwahrheit hilft dabei, die Qualität der erzielten Modelle zu bewerten. 

------------------------------------------------------------------------



## Phase 3 Optimierung

Optimierung mit Differential Evolution (DE):
Die Funktion DEinterface (auskommentierter Code) ist eine Wrapper-Funktion für die Optimierung mit Differential Evolution (DE). DE ist ein Optimierungsalgorithmus, der hier genutzt wird, um die besten Parameter für die Funktionen zu finden. Der Algorithmus wird auf die Grundwahrheit (groundtruth), das RNN-Modell (rnn) und das Gaußprozess-Regressionsmodell (gauss) angewendet.

Experiment-Protokollierung:
Die Funktion logExperiment führt das DE-Experiment für verschiedene Modelle durch und protokolliert die Ergebnisse. Dabei werden die Grundwahrheit, das RNN-Modell und das Gaußprozess-Modell verglichen.

Benchmarks für verschiedene Populationen:
Die Experimente werden für verschiedene Populationsgrößen (popSize) durchgeführt: 4, 20 und 40 mal die Dimension. Die Ergebnisse werden in log1, log2 und log3 gespeichert.

Chancen und Gründe für eine kleine Populationsgröße (popSize = 4):

Schnellere Ausführung: Eine kleinere Populationsgröße erfordert weniger Berechnungen, was zu einer schnelleren Durchführung der Optimierung führt. Dies kann vorteilhaft sein, wenn die Zeit für die Durchführung der Optimierung begrenzt ist.
Exploration: Eine kleinere Populationsgröße ermöglicht eine schnellere Exploration des Suchraums. Dies kann dazu führen, dass der Algorithmus eine breitere Palette von Lösungen in kürzerer Zeit erkundet.
Chancen und Gründe für eine moderate Populationsgröße (popSize = 20):

Ausgewogenheit zwischen Exploration und Exploitation: Eine moderate Populationsgröße ermöglicht sowohl die Exploration des Suchraums als auch eine bessere Ausnutzung bereits entdeckter vielversprechender Bereiche. Es besteht eine gute Balance zwischen der Breite der Suche und der Vertiefung in vielversprechende Regionen.
Chancen und Gründe für eine größere Populationsgröße (popSize = 40 mal die Dimension):

Bessere Konvergenz: Eine größere Populationsgröße kann dazu beitragen, dass der Algorithmus schneller gegen Ende der Optimierung konvergiert. Dadurch besteht die Möglichkeit, in den letzten Iterationen genauere und genauere Lösungen zu finden.
Höhere Genauigkeit: Eine größere Populationsgröße ermöglicht eine bessere Schätzung der Parameter und Funktionen, was zu einer höheren Genauigkeit der gefundenen Lösungen führen kann.

Zusammenfassend kann man sagen, dass ein Ansatz mit popSize = 4 einige Gemeinsamkeiten mit gradientenbasierten Ansätzen aufweisen kann, insbesondere wenn es darum geht, lokal optimale Lösungen zu finden. Dennoch sind evolutionäre Algorithmen in der Regel weniger anfällig für das Steckenbleiben in lokalen Minima und können eine breitere Exploration des Suchraums ermöglichen. 

Auswertung der Benchmarks und Plots:
Die Funktion plotBenchmark generiert verschiedene Benchmark-Plots, um die Leistung der Modelle zu vergleichen. Die Funktion plotBenchmarkPerformance wird verwendet, um die Performance der Modelle hinsichtlich der Funkevals darzustellen. Die Funktion plotBenchmarkValidation zeigt die Validierung der Modelle anhand der Funkevals.

Ausgabe der Ergebnisse:
Die Ergebnisse der Optimierungsexperimente werden ausgegeben. Dies umfasst sowohl die Benchmark-Plots als auch die Zeiten, die für die Optimierung mit den verschiedenen Modellen benötigt wurden.



|-> Abbruchkriterium auf zu hohem Wert, bzw. wird zu schnell erreicht
|-> 





